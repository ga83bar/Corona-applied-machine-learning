

\doxysection*{R\+E\+A\+D\+ME -\/ What If AI}





R\+E\+A\+D\+ME for group 11 of the 2020 Applied Machine Intelligence lecture at T\+UM. 

\doxysubsection*{Table of contents}

\mbox{[}\mbox{[}{\itshape T\+OC}\mbox{]}\mbox{]}

\doxysubsection*{Short project description}

This project aims to quantify the impact that the Covid-\/19 pandemic has on the global economy, utilising machine learning. One of the main limitations in machine learning is the modelling of unsampled regions in the feature space. Furthermore, models learned during the training process are only valid in the context of unchanged underlying data generation processes. Since the Covid-\/19 pandemic fundamentally changed the way our society operates, and we don\textquotesingle{}t have any samples of a global pandemic of smaller and/or greater size, it is impossible to directly model the impact of the virus on different branches of the economy. Instead, we aim to model the economy without the pandemic ensuing from January 2020 on. The impact of the pandemic can then be measured as the difference of the predicted courses without Covid-\/19, and the actual, observed outcomes. The models and its predictions are made accessible with an interactive web interface.

\doxysubsection*{Requirements}

In order to run the project, you need to have Docker and docker-\/compose installed on your machine. Running the project with Docker takes care of installing the correct project dependencies and environments.

\doxysubsection*{How to use}

After cloning the directory, you can start the project by running the \href{/docker-compose.yml}{\texttt{ docker-\/compose}} file. This starts both the front-\/ and the backend of our web server. Both docker containers for the front-\/ and backend will build and start up automatically. You can now access the webpage using any browser of your liking at \href{http://localhost:8080/\#/}{\texttt{ http\+://localhost\+:8080/\#/}}.

\begin{quote}
$\ast$$\ast$\+\_\+\+N\+O\+TE\+:\+\_\+$\ast$$\ast$ Start the docker-\/compose from the root directory of the project using\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{<user>:\string~\$ docker-\/compose up}
\end{DoxyCode}


\end{quote}


\doxysubsection*{File structure}

\doxysubsubsection*{Data sets}

All data sets can be found in the \href{/res}{\texttt{ res}} folder. Most Subsets have their own R\+E\+A\+D\+ME explaining particular details for this individual set such as the location of related code or comments on the quality. ~\newline


\begin{quote}
$\ast$$\ast$\+\_\+\+N\+O\+TE\+:\+\_\+$\ast$$\ast$ Not all data sets were used in the final project. \end{quote}


\doxysubsubsection*{Documentation}

The project documentation can be found in the \href{/documentation}{\texttt{ documentation}} folder. It includes all milestone reports as well as some meeting transcripts.

\doxysubsubsection*{Code base}

Our code base is located in the \href{/src}{\texttt{ src}} folder. Scrapers, A\+PI scripts etc. to obtain raw data can be found in the \href{/src/data_collection}{\texttt{ data\+\_\+collection}} folder. Basic preprocessing and data extraction scripts are located in \href{/src/data_management}{\texttt{ data\+\_\+management}}. The unified data preprocessing scripts are saved in \href{/src/data_pipeline}{\texttt{ data\+\_\+pipeline}}. The code for training, final model evaluation and live inference for the web interface is located in \href{/src/inference}{\texttt{ inference}}. Finally, \href{/src/webinterface}{\texttt{ webinterface}} contains the code for both front-\/ and backend. ~\newline
 
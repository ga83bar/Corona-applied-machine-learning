\doxysection*{Table of Contents}

\mbox{[}\mbox{[}{\itshape T\+OC}\mbox{]}\mbox{]}

\doxysection*{Member Attendances}

The following members are on vacation and thus not present\+:


\begin{DoxyItemize}
\item Max Putz\+: 20.\+8. -\/ 3.\+9. (not available)
\item Aron\+: 22.\+9. -\/ 5.\+9. (still available)
\end{DoxyItemize}

\doxysection*{Quick Summary}

This underlying document summarizes measures and ideas for the current ML modeling process which were agreed upon in the first meeting. In particular, it highlightens the {\bfseries{four main categories}} as well as the respective {\bfseries{responsible group members}}.

\doxysection*{Status}

{\bfseries{Next Meeting\+:}} Thursday, 20.\+8. @1.\+30pm

{\bfseries{To Do}}

{\itshape General}
\begin{DoxyItemize}
\item \mbox{[}x\mbox{]} Create an ML Overview Document
\end{DoxyItemize}

{\itshape Step 1}
\begin{DoxyItemize}
\item \mbox{[} \mbox{]} E\+LM model trained and validated
\item \mbox{[} \mbox{]} Creme model trained and validated
\item \mbox{[} \mbox{]} Prophet model trained and validated
\end{DoxyItemize}

{\itshape Step 2}
\begin{DoxyItemize}
\item \mbox{[} \mbox{]} Defined what to do exactly
\item \mbox{[} \mbox{]} ...
\end{DoxyItemize}

{\itshape Step 3}
\begin{DoxyItemize}
\item \mbox{[} \mbox{]} Cross-\/validation data set determined
\item \mbox{[} \mbox{]} Cross-\/validation data set created
\item \mbox{[} \mbox{]} ...
\end{DoxyItemize}

{\itshape Step 4}
\begin{DoxyItemize}
\item \mbox{[} \mbox{]} Integration parameters defined
\item \mbox{[} \mbox{]} ...
\end{DoxyItemize}

\doxysection*{1 Model Architecture Development}

In order to catch up on the {\bfseries{clearly failed tasks of Milestone 3}}, we compare {\bfseries{three different model approaches}} from which we are sure that reasonably good approximations w.\+r.\+t. overfitting, etc. are definitely possible. ~\newline


The models are all trained and validated on the {\bfseries{four core data sets}}\+:
\begin{DoxyItemize}
\item Stock Market
\item Internet Exchanges (IX)
\item Twitch
\item Playstation
\end{DoxyItemize}

This way, we also intend to {\bfseries{compare}} different approaches for different data sets, another aspect initially {\bfseries{expected in Milestone 3}}.

\doxysubsection*{E\+L\+Ms}


\begin{DoxyItemize}
\item Responsibility\+: {\bfseries{Michael Brandner}}
\item Modeling is pursued using Extreme Learning Machines\+: /documentation/\+Machine Learning \mbox{\hyperlink{MachineLearningModels_8md}{Models/\+Machine\+Learning\+Models.\+md}} \char`\"{}\+General E\+L\+M Architecture\char`\"{}
\end{DoxyItemize}

\doxysubsection*{Online Learning}


\begin{DoxyItemize}
\item Responsibility\+: {\bfseries{Alexander Griessel}}
\item Online modeling is pursued using \href{https://creme-ml.github.io/}{\texttt{ creme}}.
\end{DoxyItemize}

{\bfseries{What is creme?}} $>$creme is a Python library for online machine learning. All the tools in the library can be updated with a single observation at a time, and can therefore be used to learn from streaming data. This is general-\/purpose library, and therefore caters to different machine learning problems, including regression, classification, and unsupervised learning.

\doxysubsection*{Time-\/\+Series Forecasting}


\begin{DoxyItemize}
\item Responsibility\+: {\bfseries{Aron Endres}}
\item Time-\/series modeling is pursued using \href{https://facebook.github.io/prophet/}{\texttt{ Prophet}}
\end{DoxyItemize}

{\bfseries{What is Prophet?}} $>$Prophet is a procedure for forecasting time series data based on an additive model where non-\/linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.

$>$Prophet is open source software released by Facebookâ€™s Core Data Science team. It is available for download on C\+R\+AN and Py\+PI.

\doxysection*{2 Data Processing}

Essential data processing \& preparation regarding things like {\bfseries{time window size}}, etc. has to be undergone before any of above models are applied. This way, a somewhat unitary data base is used for comparison.


\begin{DoxyItemize}
\item Responsibility\+: {\bfseries{Henrique Frutuoso}}
\item The main files to be considered in this step are already pushed, see $\ast$/res/inference$\ast$
\end{DoxyItemize}

\doxysection*{3 Cross-\/\+Validation}

Estimated model outputs need to be cross-\/validated. The main strategy is still {\bfseries{undetermined and tba}}, though every model analyst in {\itshape Step 1} is recquired to firstly cross-\/validate on their own. In {\itshape Step 3} we want to {\bfseries{compare}} the respective models on a unified cross-\/validation data set. This way, we can imply -\/ as mentioned above -\/ which model architecture would perform {\bfseries{better (or worse)}} for Stock Market, IX, Twitch and Playstation data sets.


\begin{DoxyItemize}
\item Responsibility\+: {\bfseries{Henrique Frutuoso, Aladin Djuhera}}
\end{DoxyItemize}

\doxysection*{4 Integration}

In order to {\bfseries{seamlessly integrate}} the mathematical models to the web-\/interface, integration needs to be defined beforehand, i.\+e. essential parameters such as time windows, etc. need to be communicated. In other words, front-\/ and back-\/end need to be properly defined and connected.


\begin{DoxyItemize}
\item Responsibility\+: {\bfseries{Niklas Landerer}} 
\end{DoxyItemize}
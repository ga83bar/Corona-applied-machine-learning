\hypertarget{namespacescrape}{}\doxysection{scrape Namespace Reference}
\label{namespacescrape}\index{scrape@{scrape}}


Main script for scraping from Socialblade.  


\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
def \mbox{\hyperlink{namespacescrape_aea10499452d562a9e13dc07d9ef7405f}{load\+\_\+channel\+\_\+urls}} (package\+\_\+id)
\begin{DoxyCompactList}\small\item\em Loads the channel urls from the package directory. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a43cb6f05b6e5ed2d6d9872445597877e}{load\+\_\+quicksave}} (package\+\_\+id)
\begin{DoxyCompactList}\small\item\em Loads a quicksave from the package directory. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a3ce572e5ef7206135fcab42e292a6349}{clear\+\_\+dictionary}} (package\+\_\+id)
\begin{DoxyCompactList}\small\item\em Clears all files from the package directory. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a24121be448d7bacd5082cacbb3ce4813}{write\+\_\+results}} (results, package\+\_\+id)
\begin{DoxyCompactList}\small\item\em Writes the results to the package directory. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a0f759a85c4ca484e05a586af8d3baba5}{quicksave}} (channel\+\_\+url\+\_\+list, results, package\+\_\+id)
\begin{DoxyCompactList}\small\item\em Stores a quicksave to the package directory. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a832e389ce44f72dba244fdd9e2a68a14}{change\+\_\+vpn}} (server)
\begin{DoxyCompactList}\small\item\em Changes the connections V\+PN server. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a972aef5843ba9c0737fb3199b952026e}{get\+\_\+vpn\+\_\+servers}} ()
\begin{DoxyCompactList}\small\item\em Loads a list of available Nord\+V\+PN servers. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{namespacescrape_a5653dd5601f9b92af6a260a7fab1ff43}{main}} ()
\begin{DoxyCompactList}\small\item\em Main function of the docker scrape script. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
string \mbox{\hyperlink{namespacescrape_adc4ab94f4f796ac74a9d12e69b9c7744}{P\+A\+TH}} = \char`\"{}/\char`\"{}
\item 
\mbox{\hyperlink{namespacescrape_a83c42217e2043cfd401f6f5905a161de}{P\+A\+C\+K\+A\+G\+E\+\_\+\+ID}} = os.\+environ\mbox{[}\textquotesingle{}P\+A\+C\+K\+A\+GE\textquotesingle{}\mbox{]}
\item 
string \mbox{\hyperlink{namespacescrape_a09c2beb51a012b7dbddb4f09160261f0}{L\+O\+A\+D\+\_\+\+S\+A\+VE}} = \char`\"{}yes\char`\"{}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Main script for scraping from Socialblade. 

To get as much data as possible from the website, we look for the top 250 channels in more than 240 available country options for a total of $>$ 60.\+000 channels. These channels are the most successful ones in their respective country, so we assume the data to be representative of the countries Youtube activities.

First, the scraper gets all available country top channel urls and assembles work packages from the results. Then docker containers are used to connect to a V\+PN, each with a different IP to avoid blocking by Cloudflare. Each container gets a work package assigned. Once all containers finished scraping for the urls of the top 250 channels per country, new work packages are created and again assigned to docker containers with random I\+Ps. After completion of all tasks, the data gets assembled into a single data file. 

\doxysubsection{Function Documentation}
\mbox{\Hypertarget{namespacescrape_a832e389ce44f72dba244fdd9e2a68a14}\label{namespacescrape_a832e389ce44f72dba244fdd9e2a68a14}} 
\index{scrape@{scrape}!change\_vpn@{change\_vpn}}
\index{change\_vpn@{change\_vpn}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{change\_vpn()}{change\_vpn()}}
{\footnotesize\ttfamily def scrape.\+change\+\_\+vpn (\begin{DoxyParamCaption}\item[{}]{server }\end{DoxyParamCaption})}



Changes the connections V\+PN server. 

\begin{DoxyWarning}{Warning}
We use Nord\+V\+PN for our connection. This function will only work with the correct Nord\+V\+PN setup and installations.
\end{DoxyWarning}

\begin{DoxyParams}{Parameters}
{\em server} & The Nord\+V\+PN server address to connect to as string. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{namespacescrape_a3ce572e5ef7206135fcab42e292a6349}\label{namespacescrape_a3ce572e5ef7206135fcab42e292a6349}} 
\index{scrape@{scrape}!clear\_dictionary@{clear\_dictionary}}
\index{clear\_dictionary@{clear\_dictionary}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{clear\_dictionary()}{clear\_dictionary()}}
{\footnotesize\ttfamily def scrape.\+clear\+\_\+dictionary (\begin{DoxyParamCaption}\item[{}]{package\+\_\+id }\end{DoxyParamCaption})}



Clears all files from the package directory. 


\begin{DoxyParams}{Parameters}
{\em package\+\_\+id} & ID of the work package. Specifies the folder to load. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{namespacescrape_a972aef5843ba9c0737fb3199b952026e}\label{namespacescrape_a972aef5843ba9c0737fb3199b952026e}} 
\index{scrape@{scrape}!get\_vpn\_servers@{get\_vpn\_servers}}
\index{get\_vpn\_servers@{get\_vpn\_servers}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{get\_vpn\_servers()}{get\_vpn\_servers()}}
{\footnotesize\ttfamily def scrape.\+get\+\_\+vpn\+\_\+servers (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Loads a list of available Nord\+V\+PN servers. 

Server list is filtered to only include servers below 50\% capacity and shuffled.

\begin{DoxyReturn}{Returns}
Returns a list of available servers. 
\end{DoxyReturn}
\mbox{\Hypertarget{namespacescrape_aea10499452d562a9e13dc07d9ef7405f}\label{namespacescrape_aea10499452d562a9e13dc07d9ef7405f}} 
\index{scrape@{scrape}!load\_channel\_urls@{load\_channel\_urls}}
\index{load\_channel\_urls@{load\_channel\_urls}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{load\_channel\_urls()}{load\_channel\_urls()}}
{\footnotesize\ttfamily def scrape.\+load\+\_\+channel\+\_\+urls (\begin{DoxyParamCaption}\item[{}]{package\+\_\+id }\end{DoxyParamCaption})}



Loads the channel urls from the package directory. 


\begin{DoxyParams}{Parameters}
{\em package\+\_\+id} & ID of the work package. Specifies the folder to load. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Returns the list of channel urls saved in the job. 
\end{DoxyReturn}
\mbox{\Hypertarget{namespacescrape_a43cb6f05b6e5ed2d6d9872445597877e}\label{namespacescrape_a43cb6f05b6e5ed2d6d9872445597877e}} 
\index{scrape@{scrape}!load\_quicksave@{load\_quicksave}}
\index{load\_quicksave@{load\_quicksave}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{load\_quicksave()}{load\_quicksave()}}
{\footnotesize\ttfamily def scrape.\+load\+\_\+quicksave (\begin{DoxyParamCaption}\item[{}]{package\+\_\+id }\end{DoxyParamCaption})}



Loads a quicksave from the package directory. 


\begin{DoxyParams}{Parameters}
{\em package\+\_\+id} & ID of the work package. Specifies the folder to load. \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
Returns the quicksave dictionary. 
\end{DoxyReturn}
\mbox{\Hypertarget{namespacescrape_a5653dd5601f9b92af6a260a7fab1ff43}\label{namespacescrape_a5653dd5601f9b92af6a260a7fab1ff43}} 
\index{scrape@{scrape}!main@{main}}
\index{main@{main}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{main()}{main()}}
{\footnotesize\ttfamily def scrape.\+main (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Main function of the docker scrape script. 

Uses the environment variables to scrape the assigned work package and takes care of scraping error handling. Scraping is done with quicksaves to be able to continue the work in case an unforeseen error appears. \mbox{\Hypertarget{namespacescrape_a0f759a85c4ca484e05a586af8d3baba5}\label{namespacescrape_a0f759a85c4ca484e05a586af8d3baba5}} 
\index{scrape@{scrape}!quicksave@{quicksave}}
\index{quicksave@{quicksave}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{quicksave()}{quicksave()}}
{\footnotesize\ttfamily def scrape.\+quicksave (\begin{DoxyParamCaption}\item[{}]{channel\+\_\+url\+\_\+list,  }\item[{}]{results,  }\item[{}]{package\+\_\+id }\end{DoxyParamCaption})}



Stores a quicksave to the package directory. 


\begin{DoxyParams}{Parameters}
{\em channel\+\_\+url\+\_\+list} & The list of still unhandled urls. \\
\hline
{\em results} & The results array that was assembled so far. \\
\hline
{\em package\+\_\+id} & ID of the work package. Specifies the folder to load. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{namespacescrape_a24121be448d7bacd5082cacbb3ce4813}\label{namespacescrape_a24121be448d7bacd5082cacbb3ce4813}} 
\index{scrape@{scrape}!write\_results@{write\_results}}
\index{write\_results@{write\_results}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{write\_results()}{write\_results()}}
{\footnotesize\ttfamily def scrape.\+write\+\_\+results (\begin{DoxyParamCaption}\item[{}]{results,  }\item[{}]{package\+\_\+id }\end{DoxyParamCaption})}



Writes the results to the package directory. 


\begin{DoxyParams}{Parameters}
{\em results} & The result array that is to be saved. \\
\hline
{\em package\+\_\+id} & ID of the work package. Specifies the folder to load. \\
\hline
\end{DoxyParams}


\doxysubsection{Variable Documentation}
\mbox{\Hypertarget{namespacescrape_a09c2beb51a012b7dbddb4f09160261f0}\label{namespacescrape_a09c2beb51a012b7dbddb4f09160261f0}} 
\index{scrape@{scrape}!LOAD\_SAVE@{LOAD\_SAVE}}
\index{LOAD\_SAVE@{LOAD\_SAVE}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{LOAD\_SAVE}{LOAD\_SAVE}}
{\footnotesize\ttfamily string scrape.\+L\+O\+A\+D\+\_\+\+S\+A\+VE = \char`\"{}yes\char`\"{}}

\mbox{\Hypertarget{namespacescrape_a83c42217e2043cfd401f6f5905a161de}\label{namespacescrape_a83c42217e2043cfd401f6f5905a161de}} 
\index{scrape@{scrape}!PACKAGE\_ID@{PACKAGE\_ID}}
\index{PACKAGE\_ID@{PACKAGE\_ID}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{PACKAGE\_ID}{PACKAGE\_ID}}
{\footnotesize\ttfamily scrape.\+P\+A\+C\+K\+A\+G\+E\+\_\+\+ID = os.\+environ\mbox{[}\textquotesingle{}P\+A\+C\+K\+A\+GE\textquotesingle{}\mbox{]}}

\mbox{\Hypertarget{namespacescrape_adc4ab94f4f796ac74a9d12e69b9c7744}\label{namespacescrape_adc4ab94f4f796ac74a9d12e69b9c7744}} 
\index{scrape@{scrape}!PATH@{PATH}}
\index{PATH@{PATH}!scrape@{scrape}}
\doxysubsubsection{\texorpdfstring{PATH}{PATH}}
{\footnotesize\ttfamily string scrape.\+P\+A\+TH = \char`\"{}/\char`\"{}}

